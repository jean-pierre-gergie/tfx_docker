{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d098533b-1a18-4faf-8104-6586705f2418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess, shutil, json\n",
    "import pyspark, tfx, apache_beam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6534ae22-c902-4a49-b51c-3f75d2cfc0b3",
   "metadata": {},
   "source": [
    "## ENV Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff607a2-772f-4646-8a76-e6dbfcf73bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFX: 1.16.0\n",
      "Beam: 2.59.0\n",
      "SPARK_HOME: /home/jpg/miniconda3/envs/tfx-spark-env/lib/python3.10/site-packages/pyspark\n",
      "JAVA_HOME: /home/jpg/miniconda3/envs/tfx-spark-env\n"
     ]
    }
   ],
   "source": [
    "SPARK_HOME = os.path.dirname(pyspark.__file__)\n",
    "JAVA_BIN = shutil.which(\"java\")\n",
    "JAVA_HOME = os.path.dirname(os.path.dirname(os.path.realpath(JAVA_BIN))) if JAVA_BIN else \"\"\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = SPARK_HOME\n",
    "os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
    "os.environ[\"PATH\"] = f'{os.path.join(SPARK_HOME,\"bin\")}:{os.environ[\"PATH\"]}'\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "os.environ[\"SPARK_LOCAL_IP\"] = os.environ.get(\"SPARK_LOCAL_IP\",\"127.0.0.1\")  # match the job server bind\n",
    "\n",
    "print(\"TFX:\", tfx.__version__)\n",
    "print(\"Beam:\", apache_beam.__version__)\n",
    "print(\"SPARK_HOME:\", os.environ[\"SPARK_HOME\"])\n",
    "print(\"JAVA_HOME:\", os.environ[\"JAVA_HOME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b160d0d-0ee4-4405-8888-5bfae5c627b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/jpg/miniconda3/envs/tfx-spark-env/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/28 10:57:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.2.3\n",
      "openjdk version \"11.0.1\" 2018-10-16 LTS\n",
      "OpenJDK Runtime Environment Zulu11.2+3 (build 11.0.1+13-LTS)\n",
      "OpenJDK 64-Bit Server VM Zulu11.2+3 (build 11.0.1+13-LTS, mixed mode)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"sanity\").getOrCreate()\n",
    "print(\"Spark version:\", spark.version)\n",
    "spark.stop()\n",
    "\n",
    "import subprocess, shlex\n",
    "print(subprocess.check_output(shlex.split(\"java -version\"), stderr=subprocess.STDOUT).decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba57d072-a8ed-460d-b83e-86adcbc80748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tempfile, pathlib\n",
    "os.environ[\"SEMI_PERSISTENT_DIRECTORY\"] = str(pathlib.Path(tempfile.gettempdir())/\"beam_scratch\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9192199-8d62-4a1d-a744-36e45791c54a",
   "metadata": {},
   "source": [
    "## POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf30d67-7f07-4aab-a959-2c0bf3a500e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 10:57:06.498789: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-28 10:57:06.535911: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-28 10:57:06.535949: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "from tfx.orchestration import pipeline as tfx_pipeline\n",
    "from tfx.orchestration.metadata import sqlite_metadata_connection_config\n",
    "from tfx.components import CsvExampleGen, StatisticsGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ce13ff-bf92-4ec6-a095-2de27c85133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = '/home/jpg/Desktop/tfx-spark'\n",
    "PIPELINE_NAME = \"tfx_spark_demo_parquet\"\n",
    "PIPELINE_ROOT = os.path.join(HOME, \"tfx\", \"pipelines\", PIPELINE_NAME)\n",
    "METADATA_PATH = os.path.join(HOME, \"tfx\", \"metadata\", PIPELINE_NAME, \"metadata.db\")\n",
    "DATA_ROOT = os.path.join(HOME, \"tfx\", \"data\", \"parquet_demo\")\n",
    "os.makedirs(PIPELINE_ROOT, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(METADATA_PATH), exist_ok=True)\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace38129-3377-49ff-9ec4-c655f5571846",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6fffd-262d-4591-a4a2-088a5086fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen = CsvExampleGen(input_base=DATA_ROOT)\n",
    "stats_gen = StatisticsGen(examples=example_gen.outputs[\"examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9646a-c673-421c-9fbd-a8d4f67ceb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_pipeline_args = [\n",
    "    \"--runner=DirectRunner\",\n",
    "    \"--direct_running_mode=multi_processing\",\n",
    "    \"--direct_num_workers=4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37acd187-c721-41bb-a51b-df2a9abdacbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_config = sqlite_metadata_connection_config(METADATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f28ab-d39c-4a2e-beb0-258c7f9de17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline():\n",
    "    return tfx_pipeline.Pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        components=[example_gen, stats_gen],\n",
    "        metadata_connection_config=metadata_config,\n",
    "        enable_cache=True,\n",
    "        beam_pipeline_args=beam_pipeline_args,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9210b6-83d3-44d9-897e-34775a19165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BeamDagRunner().run(build_pipeline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39083b05-4278-47ee-9d89-717c80773dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b94e9b7-6975-45d5-956a-22208a3dd4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFX Spark (py310)",
   "language": "python",
   "name": "tfx-spark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
